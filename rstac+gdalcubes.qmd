---
title: "Creating a raster cube from STAC items from EOPF using rstac and gdalcubes"
format: html
author: "Christian" 
self-contained: true
---

This now also works on Windows when using R-devel and rtools >=6690, where an issue with reading blosc compressed files using gdal was fixed, see [here](https://github.com/r-spatial/stars/issues/663#issuecomment-3435761956) 

After installing R-devel and rtools, install `sf` and `gdalcubes` from source.

```{r}
#install.packages("sf", type = "source")
#install.packages("gdalcubes", type = "source")
library(rstac)
library(gdalcubes)
library(sf)
```

### Create image collection from STAC items 
We can convert STAC items received through `rstac` to gdalcubes image collections using the function `stac_image_collection()`.
From there on, we can create raster cubes as usual. See also [Marius´ tutorial](https://gdalcubes.github.io/source/tutorials/vignettes/gc02_AWS_Sentinel2.html) on the example of the Sentinel-2 COG catalog on Amazon Web Services (AWS). For using this with the EOPF Zarr STAC API, we need to adapt the download function a little bit (see below).


Finding STAC items from EOPF STAC API with `rstac`:
```{r}	
# Using a bbox roughly for "Münsterland" and June 2025.
# For the stac request, I need the bbox in WGS84
# We limit the no of results to 5 for testing purposes
bbox_wgs84 <- st_bbox(c(xmin = 6.55, xmax = 7.8, ymin = 51.8, ymax = 52.4), crs = st_crs(4326))
bbox_utm =st_transform(bbox_wgs84, "EPSG:32632")

stac_source = stac("https://stac.core.eopf.eodc.eu/")
  items = stac_source |>
    stac_search(collections = "sentinel-2-l2a",
    datetime = "2025-06-01T00:00:00Z/2025-06-30T23:59:59Z",
    bbox = c(bbox_wgs84["xmin"],bbox_wgs84["ymin"],
                       bbox_wgs84["xmax"],bbox_wgs84["ymax"]), limit = 5) |>
    post_request() 
  length(items$features)

items

###--> adapt download function to adapt the URL such that it points to the actual ZARR file 
f = function(href) {
  return(paste0("ZARR:\"/vsicurl/", gsub(".zarr/", ".zarr\"/", href)))
}
```

Why adapt the function?
```{r}
items$features[[1]]$assets$B02_10m$href #--> this is what you get from stac, 
# but what you want - in order for GDAL to understand it- is the URL to the .zarr file; 
# see tutorial: https://eopf-sample-service.github.io/eopf-sample-notebooks/gdal-explore-zarr/
# the function above replaces the href by one that directs directly there 
# --> since you can give this as an argument to stac_image_collection(), it will be applied to all assets

```

```{r}
### Create image collection from stac items
# set argument "srs", because gdalcubes looks for proj:epsg, but in the collection there is only proj:code
# also: since the items found are not all in the same UTM zone, I want to filter them first
s2_collection = stac_image_collection(items$features, srs = "EPSG:32632", asset_names = c("B02_10m", "B03_10m", "B04_10m", "B08_10m"), url_fun = f, property_filter = function(x) {x[["proj:code"]] == "EPSG:32632"})

s2_collection


```
### Create a cube view
-> here with 100m spatial resolution and daily time steps, aggregating with median
```{r}
v = cube_view(srs="EPSG:32632", dx=100, dy=100, dt="P1D",
              aggregation="median",
              extent=list(t0 = "2025-06-01", t1 = "2025-06-30",
                          left=bbox_utm["xmin"], right=bbox_utm["xmax"],
                          top=bbox_utm["ymax"], bottom=bbox_utm["ymin"]))

v
```
### Create cube 

Create a raster cube and plot (alternatively write to GeoTIFF). This is currently quite slow.
```{r}	
system.time(raster_cube(s2_collection, v) |>
  select_bands(c("B02_10m","B03_10m","B04_10m")) |>
  reduce_time(c("median(B02_10m)", "median(B03_10m)", "median(B04_10m)")) |>
  plot(rgb = 3:1, zlim = c(0,3000)))
  #write_tif("eopf_s2_munsterland_june2025_RGB_median_100m.tif"))

```

