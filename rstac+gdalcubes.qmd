---
title: "Creating a raster cube from STAC items of the EOPF Zarr Samples Service using rstac and gdalcubes"
format: html
self-contained: true
---


### Introduction

This notebook demonstrates how to create a raster cube from STAC items from the EOPF Sentinel Zarr Samples Service using the `rstac` and `gdalcubes` packages in R.
We will search for Sentinel-2 images roughly covering the MÃ¼nsterland region in Germany for June 2025, and retrieve corresponding STAC items with `rstac`. We will then use `gdalcubes` to create a raster cube and visualize an RGB plot aggregating the data to one image (using median) and resampling to 100m spatial resolution. 

The `gdalcubes` package offers powerfull functionality to create regular raster cubes from irregular image collections and manages issues such as differing spatial and temporal resolutions, partial spatial overlap or differing projections etc. It first collects images in so-called _image collections_ and creates data cubes from them, where the spatiotemporal geometry is defined via a _data cube view_. It also has a function to directly create _image collections_ from STAC items, which we will use here.
For details on the functionality and concepts, see the [gdalcubes documentation](https://gdalcubes.github.io/) and specifically [MariusÂ´ tutorial](https://gdalcubes.github.io/source/tutorials/vignettes/gc02_AWS_Sentinel2.html) on the example of the Sentinel-2 COG catalog on Amazon Web Services (AWS).


### What we will learn

- ðŸš€ Retrieve STAC items for Sentinel-2 imagery in a specified AOI (roughly "MÃ¼nsterland" region, Germany) and time range (June 2025) using `rstac`
- ðŸ”Ž Create an image collection from STAC items using `stac_image_collection()` in `gdalcubes`
- ðŸ›°ï¸ Create raster cubes with a user-defined spatiotemporal geometry using `cube_view()` and `raster_cube()` in `gdalcubes` and perform a basic NDVI change analysis


::: {.callout-note}
As you will see, we will need some tweaking of the workflow here and there, since `gdalcubes` is currently not fully prepared for working with the EOPF Sentinel Zarr Samples Service, but the functionality is there and will hopefully be streamlined in future releases.
:::

::: {.callout-note}
This now also works on Windows when using R >= 4.5.2, where an issue with reading blosc compressed files using gdal was fixed, see [here](https://github.com/r-spatial/stars/issues/663#issuecomment-3435761956) 
:::

### Prerequisites

Make sure to have R >=4.5.2. Install `rstac`, `sf` and `gdalcubes`. We will also use  `viridis` for nice color maps, so we will install it .

```{r}
#install.packages("rstac")
#install.packages("sf")
#install.packages("gdalcubes")
#install.packages("viridis")
```



### Create image collection from STAC items 
We can convert STAC items received through `rstac` to `gdalcubes` image collections using the function `stac_image_collection()`.
From there on, we can create raster cubes as usual. See also [MariusÂ´ tutorial](https://gdalcubes.github.io/source/tutorials/vignettes/gc02_AWS_Sentinel2.html). For using this with the EOPF Zarr STAC API, we need to adapt the download function a little bit (see below).


Finding STAC items from EOPF STAC API with `rstac`:
```{r}	
# Using a bbox roughly for "MÃ¼nsterland" and June 2025.
# For the stac request, I need the bbox in WGS84
# We limit the no of results to 5 for testing purposes
library(rstac)
library(gdalcubes)
library(sf)


bbox_wgs84 <- st_bbox(c(xmin = 6.55, xmax = 7.8, ymin = 51.8, ymax = 52.4), crs = st_crs(4326))
bbox_utm =st_transform(bbox_wgs84, "EPSG:32632")

stac_source = stac("https://stac.core.eopf.eodc.eu/")
  items = stac_source |>
    stac_search(collections = "sentinel-2-l2a",
    datetime = "2025-06-01T00:00:00Z/2025-06-30T23:59:59Z",
    bbox = c(bbox_wgs84["xmin"],bbox_wgs84["ymin"],
                       bbox_wgs84["xmax"],bbox_wgs84["ymax"]), limit = 5) |>
    post_request() 
  length(items$features)

items

###--> adapt download function to adapt the URL such that it prepends a necessary prefix, and points to the .zarr file
f = function(href) {
  return(paste0("ZARR:\"/vsicurl/", gsub(".zarr/", ".zarr\"/", href)))
}
```

Why adapt the function?
The items returned from our STAC request have asset hrefs like this:
```{r}
items$features[[1]]$assets$B02_10m$href 
```
In order for GDAL to use the correct driver, we need the URL with a prefix for the correct Zarr driver, see tutorial: https://eopf-sample-service.github.io/eopf-sample-notebooks/gdal-explore-zarr/
Also, we want it to point directly to the .zarr file the function above replaces the href by one that directs directly there.
Since you can give this as an argument to `stac_image_collection()`, it will be applied to all assets.


Create image collection from STAC items:
```{r}
# manually set argument "srs", because gdalcubes looks for proj:epsg, but in the collection there is only proj:code
# also: since the items found are not all in the same UTM zone, I want to filter them first
s2_collection = stac_image_collection(items$features, srs = "EPSG:32632", asset_names = c("B02_10m", "B03_10m", "B04_10m", "B08_10m"), url_fun = f, property_filter = function(x) {x[["proj:code"]] == "EPSG:32632"})

s2_collection


```
### Create a cube view
After collecting all available images in an image collection, we will now create a raster cube. For this, we first need to define a cube view, which specifies the spatio-temporal geometry of the raster cube (spatial resolution, extent, temporal resolution, time extent, etc.).
For our example, we will select a small subset (10 x 10 km) north of the city of Muenster, which includes the "Rieselfelder" bird sanctuary. 
We collect the spatio-temporal extent in a list, which we then pass to `cube_view()`. We also specify a spatial resolution of 10m and a temporal resolution of 1 day. While the Sentinel-2 satellites have a revisit time of ~5 days (plus we limited the number of items received in our STAC request), swath overlaps may in principal lead to higher temporal resolution for certain pixels, so we define 1 day here to get as much data from the image collection as we can. Even for the same day, swath overlaps between Sentinel-2 A and B may lead to certain locations being recorded twice. Thus, we also have to define an aggregation method. Here we use "first". In the unlikely case that we get data from two images per day at a certain location, we simply choose the first one we get for that day. 
Days and locations without images are handled by gdalcubes as no-data values.

```{r}


#Collect spatio-temporal extent in a list, here an 
rieselX = 404500.13
rieselY = 5765279
ext = list()
ext$left = rieselX - 5000
ext$right = rieselX + 5000
ext$bottom = rieselY - 5000
ext$top = rieselY + 5000
ext$t0 = "2025-06-01"
ext$t1 = "2025-06-30"

# Create cube view with 10m spatial and 1 day temporal resolution and the previously defined spatio-temporal extent
v = cube_view(srs="EPSG:32632", dx=10, dy=10, dt="P1D",
              aggregation="first",
              extent=ext)

v
```

As you can see, the cube view summarizes the spatio-temporal geometry of the raster cube we want to create. We can see (amongst other information) that the resultsing cube will have 1000 x 1000 pixels in space (10 km x 10 km at 10m resolution) and 30 time steps (1 per day for June 2025), though many of these pixels and time steps will be no-data values as we do not have complete daily coverage for the whole area.

### Create cube and plot an RGB and an NDVI image

Now, weÂ´ll create a raster cube using the previously defined cube view. WeÂ´ll then select the red and near-infrared bands, compute and NDVI, and aggregate the results for one month using the median. This means, that for all locations where we received data on more than one day in that month, the median of all values of that pixel throughout the month is taken --> a very basic, but easy and straightforward way to select a value that is robust against outliers (e.g. clouds). As a result, we create an composite image of the specified subset that combines all information gathered there in one month to include as few na-values and clouds as possible.



```{r}	


gdalcubes_options(parallel=4)

#plot the area, aggregated to one image using median for RGB bands
raster_cube(s2_collection, v) |>
  select_bands(c("B02_10m","B03_10m","B04_10m")) |>
  reduce_time(c("median(B02_10m)", "median(B03_10m)", "median(B04_10m)")) |> 
  plot(rgb = 3:1, zlim = c(0,3000))


# compute NDVI and aggregate to one image using median
ndvi <- raster_cube(s2_collection, v) |>
              select_bands(c("B04_10m","B08_10m")) |>
              apply_pixel("(B08_10m - B04_10m)/(B08_10m + B04_10m)", "NDVI") |>
              reduce_time(c("median(NDVI)")) 
            
plot(ndvi, zlim = c(-0.2,1),key.pos=1, col=viridis::viridis)



```

::: callout-caution
## Task
Perform a simple change detection between April and June 2025.

`gdalcubes` can also be used to compute more complex analyses, such as change analyis between two time periods. However, for a task like this it is more straightforward to use it only for preparing the inputs (cloud-free composite NDVI images for each year) and then use another package like `terra` to compute the difference image.
WeÂ´ll the same approach to create an NDVI image for the same area in April. Export both NDVI images (April and June) and use a package like `terra` to compute a simple difference image to observe changes between the two months.
:::

::: {.callout-tip collapse="true"}
## Solution: click to expand
```{r}	
library(terra)

items2 = stac_source |>
   stac_search(collections = "sentinel-2-l2a",
   datetime = "2025-04-01T00:00:00Z/2025-04-30T23:59:59Z",
   bbox = c(bbox_wgs84["xmin"],bbox_wgs84["ymin"],
                      bbox_wgs84["xmax"],bbox_wgs84["ymax"]), limit = 5) |>
   post_request() 
  

s2_collection2 = stac_image_collection(items2$features, srs = "EPSG:32632", asset_names = c("B02_10m", "B03_10m", "B04_10m", "B08_10m"), url_fun = f, property_filter = function(x) {x[["proj:code"]] == "EPSG:32632"})

ext$t0 = "2025-04-01"
ext$t1 = "2025-04-30"

v2 = cube_view(srs="EPSG:32632", dx=10, dy=10, dt="P1D",
              aggregation="first",
              extent=ext)

gdalcubes_options(parallel=4)
ndvi2 <- raster_cube(s2_collection2, v2) |>
              select_bands(c("B04_10m","B08_10m")) |>
              apply_pixel("(B08_10m - B04_10m)/(B08_10m + B04_10m)", "NDVI") |>
              reduce_time(c("median(NDVI)")) 


ndvi_april <- rast(write_tif(ndvi2))
ndvi_june <- rast(write_tif(ndvi))
ndvi_change <- ndvi_june - ndvi_april
plot(ndvi_change, main = "NDVI Change April 2025 - June 2025")




#system.time(raster_cube(s2_collection4, v4) |>
#  select_bands(c("B04_10m","B08_10m")) |>
#  reduce_time(c("median(B04_10m)","median(B08_10m)")) |>
#  apply_pixel("(B08_10m_median - B04_10m_median)/(B08_10m_median + B04_10m_median)", "NDVI") |>
#  plot(zlim = c(-0.2,1),key.pos=1, col=viridis::viridis))
```

:::